dados$alc <- as.factor(dados$alc)
dados$texto <- gsub('"', 'aspas', dados$texto)
save(dados, file="database.Rda")
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
load("database.Rda")
library(RMySQL)
clearConsole <- function(){
cat("\014")
}
initFileLog <- function(nome){
zz <- file(nome, open = "wt")
sink(zz)
sink(zz, type = "message")
}
finishFileLog <- function(nome){
sink(type = "message")
sink()
file.show(nome)
}
query <- function(sql) {
dbDataType(RMySQL::MySQL(), "a")
mydb = dbConnect(MySQL(), user='root', password='', dbname=DATABASE, host='localhost')
rs = dbSendQuery(mydb, sql);
dataBD <- fetch(rs, n=-1)
#dataBD <- fetch(rs, getNumRows(mydb, "WAVELENGTH"))
huh <- dbHasCompleted(rs)
dbClearResult(rs)
dbDisconnect(mydb)
return (dataBD)
}
print("glm")
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
load("database.Rda")
dados$repetitions[dados$repetitions > 0] <- 1
dados$repetitions[dados$repetitions == 0] <- 0
dados$longpauses[dados$longpauses > 0] <- 1
dados$longpauses[dados$longpauses == 0] <- 0
clearConsole()
library(text2vec)
library(data.table)
setDT(dados)
setkey(dados, id)
prep_fun = tolower
tok_fun = word_tokenizer
stop_words = c("aber", "als", "am", "an", "auch", "auf", "aus", "bei", "bin", "bis", "bist", "da", "dadurch", "daher", "darum", "das", "daß", "dass", "dein", "deine", "dem", "den", "der", "des", "dessen", "deshalb", "die", "dies", "dieser", "dieses", "doch", "dort", "du", "durch", "ein", "eine", "einem", "einen", "einer", "eines", "er", "es", "euer", "eure", "für", "hatte", "hatten", "hattest", "hattet", "hier", "hinter", "ich", "ihr", "ihre", "im", "in", "ist", "ja", "jede", "jedem", "jeden", "jeder", "jedes", "jener", "jenes", "jetzt", "kann", "kannst", "können", "könnt", "machen", "mein", "meine", "mit", "muß", "mußt", "musst", "müssen", "müßt", "nach", "nachdem", "nein", "nicht", "nun", "oder", "seid", "sein", "seine", "sich", "sie", "sind", "soll", "sollen", "sollst", "sollt", "sonst", "soweit", "sowie", "und", "unser", "unsere", "unter", "vom", "von", "vor", "wann", "warum", "was", "weiter", "weitere", "wenn", "wer", "werde", "werden", "werdet", "weshalb", "wie", "wieder", "wieso", "wir", "wird", "wirst", "wo", "woher", "wohin", "zu", "zum", "zur", "über")
it_train = itoken(dados$texto,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, ngram = c(1L, 2L), stopwords = stop_words)
vocab = create_vocabulary(it_train, stopwords = stop_words)
vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, vectorizer)
dataM <- as.data.frame(as.matrix(dtm_train))
dadosFinal <- subset(dados, select = -c(texto, id) )
dump(dadosFinal, "exp1_alc.csv")
dump(dataM, "exp1_bag.csv")
dadosFinal <- read.csv(file="base_completa/exp1_bag.csv", header=TRUE, sep=",")
save(dadosFinal, file="alemao_base_completa.Rda")
library(tools)
PATH_FIT <- "rda/nv/fit.Rda"
PATH_PRED <- "rda/nv/bh_pred.Rda"
PATH_IMAGE <- "rda/nv/nv.RData"
load("rda/alemao_base_completa.Rda")
print("Naive Bayes")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = dadosP[,2:ncol(dadosP)],
y = dadosP$alc,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
source(file_path_as_absolute("classificador_default.R"))
source('~/GitHub/R-testes/drunk/nv.R')
PATH_PRED <- "rda/nv/bh_pred.Rda"
PATH_IMAGE <- "rda/nv/nv.RData"
load("rda/alemao_base_completa.Rda")
print("Naive Bayes")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = dadosP[,2:ncol(dadosP)],
y = dadosP$alc,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
source(file_path_as_absolute("classificador_default.R"))
stopwords = tm::stopwords("de")
stop_words = tm::stopwords("de")
stop_words
load("rda/alemao_base_completa.Rda")
library(tools)
PATH_FIT <- "resultados/svm/fit.Rda"
PATH_PRED <- "resultados/svm/pred.Rda"
PATH_IMAGE <- "resultados/svm/image.RData"
load("rda/alemao_base_completa.Rda")
print("SVM")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = dadosP[,2:ncol(dadosP)],
y = dadosP$alc,
method = "svmRadial",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
source(file_path_as_absolute("classificador_default.R"))
library(tools)
PATH_FIT <- "resultados/nv/fit.Rda"
PATH_PRED <- "resultados/nv/pred.Rda"
PATH_IMAGE <- "resultados/nv/nv.RData"
load("rda/alemao_base_completa.Rda")
print("Naive Bayes")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = dadosP[,2:ncol(dadosP)],
y = dadosP$alc,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
library(caret)
if (!require("doMC")) {
install.packages("doMC")
}
library(doMC)
registerDoMC(4)
load(PATH_FIT)
print("Prevendo")
load(PATH_PRED)
print("Resultados")
precision <- posPredValue(bh_pred, dadosFinal$alc)
print(paste("Precision", precision, sep=" "))
a <- table(bh_pred, dadosFinal$alc)
a
load(PATH_FIT)
importance <- varImp(fit, scale=FALSE)
if (!require("mlbench")) {
install.packages("mlbench")
}
set.seed(7)
library(mlbench)
importance <- varImp(fit, scale=FALSE)
fit
if (!require("mlbench")) {
install.packages("mlbench")
}
library(mlbench)
importance <- varImp(fit, scale=FALSE)
library(caret)
importance <- varImp(fit, scale=FALSE)
print(importance)
print(importance)
plot(importance)
print(importance)
print(importance[1:20])
print(importance)
print(importance[1:10,1:2])
print(importance[1:10,1])
print(importance[1:10,2])
print(importance[1:10])
dt <- as.data.frame(importance)
print(importance)
importance
clearConsole()
head(importance)
print(importance)
head(importance)
plot(importance, top = 20)
library(tools)
PATH_FIT <- "resultados/svm/fit.Rda"
PATH_PRED <- "resultados/svm/pred.Rda"
PATH_IMAGE <- "resultados/svm/image.RData"
load("rda/alemao_base_completa.Rda")
print("SVM")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = subset(dadosP, select = -c(alc)),
y = dadosP$alc,
method = "svmRadial",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
source(file_path_as_absolute("classificador_default.R"))
load(PATH_FIT)
importantes()
importantes(fit)
source(file_path_as_absolute("classificador_default.R"))
importantes(fit)
source(file_path_as_absolute("aspectos.R"))
load(PATH_FIT)
importantes(fit)
library(doMC)
detectCores()
library(tools)
PATH_FIT <- "resultados/svm/fit.Rda"
PATH_PRED <- "resultados/svm/pred.Rda"
PATH_IMAGE <- "resultados/svm/image.RData"
load("rda/alemao_base_completa.Rda")
dadosFinal2 <- data.frame(dadosFinal)
if (!require("doParallel")) {
install.packages("doParallel")
}
library(doParallel);
cl <- makeCluster(8);
registerDoParallel(cl);
library(caret)
library(tools)
source(file_path_as_absolute("functions.R"))
FILE_READ <- "testes/tweet_data_my.Rda"
FIT_SAVE <- "testes/tweet_fit_data_my.Rda"
dat = read.csv("teste/tweet_data_my.csv", header = TRUE)
dat = read.csv("testes/tweet_data_my.csv", header = TRUE)
save(dat, file = FILE_READ)
load(FILE_READ)
dadosFinal <- as.data.frame(dat)
print("Resultado Final")
dadosFinal <- as.data.frame(unclass(dadosFinal))
colnames(dat)
if (!require("doParallel")) {
install.packages("doParallel")
}
library(doParallel);
cl <- makeCluster(8);
dadosFinal$id <- NULL
if (!require("rowr")) {
install.packages("rowr")
}
library(rowr)
print("NV")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = dadosP,
y = dadosP$alc,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
print("Treinando")
fit <- trainAlgoritmo(dadosFinal)
library(tools)
source(file_path_as_absolute("functions.R"))
FILE_READ <- "testes/tweet_data_my.Rda"
FIT_SAVE <- "testes/tweet_fit_data_my.Rda"
dat = read.csv("testes/tweet_data_my.csv", header = TRUE)
save(dat, file = FILE_READ)
load(FILE_READ)
dadosFinal <- as.data.frame(dat)
dadosFinal <- as.data.frame(unclass(dadosFinal))
if (!require("doParallel")) {
install.packages("doParallel")
}
library(doParallel);
cl <- makeCluster(8);
dadosFinal <- subset(dadosFinal, select = -c(id) )
if (!require("rowr")) {
install.packages("rowr")
}
library(rowr)
print("NV")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = dadosP,
y = dadosP$q1,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
print("Treinando")
fit <- trainAlgoritmo(dadosFinal)
View(dadosFinal)
print("NV")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = subset(dadosP, select = -c(q1)),
y = dadosP$q1,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
print("Treinando")
fit <- trainAlgoritmo(dadosFinal)
#options(max.print = 99999999)
#Carrega functions
library(tools)
source(file_path_as_absolute("functions.R"))
FILE_READ <- "testes/tweet_data_my.Rda"
FIT_SAVE <- "testes/tweet_fit_data_my.Rda"
dat = read.csv("testes/tweet_data_my.csv", header = TRUE)
save(dat, file = FILE_READ)
load(FILE_READ)
dadosFinal <- as.data.frame(dat)
#print("Resultado Final")
#initFileLog("aaaaa.txt")
#cols <- colnames(dadosFinal)
#cols[1:50]
#print(cols)
#finishFileLog("aaaaa.txt")
#dadosFinal <- as.data.frame(unclass(dadosFinal))
dadosFinal$q1 <- as.factor(dadosFinal$q1)
if (!require("doParallel")) {
install.packages("doParallel")
}
library(doParallel);
cl <- makeCluster(8);
dadosFinal <- subset(dadosFinal, select = -c(id) )
if (!require("rowr")) {
install.packages("rowr")
}
library(rowr)
print("NV")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = subset(dadosP, select = -c(q1)),
y = dadosP$q1,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
print("Treinando")
fit <- trainAlgoritmo(dadosFinal)
fit
fit <- trainAlgoritmo(dadosFinal)
View(dadosFinal)
dadosFinal <- subset(dadosFinal, select = -c(id, q1) )
dadosFinal <- subset(dadosFinal, select = -c(id, q1) )
#options(max.print = 99999999)
#Carrega functions
library(tools)
source(file_path_as_absolute("functions.R"))
FILE_READ <- "testes/tweet_data_my.Rda"
FIT_SAVE <- "testes/tweet_fit_data_my.Rda"
dat = read.csv("testes/tweet_data_my.csv", header = TRUE)
save(dat, file = FILE_READ)
load(FILE_READ)
dadosFinal <- as.data.frame(dat)
#print("Resultado Final")
#initFileLog("aaaaa.txt")
#cols <- colnames(dadosFinal)
#cols[1:50]
#print(cols)
#finishFileLog("aaaaa.txt")
#dadosFinal <- as.data.frame(unclass(dadosFinal))
dadosFinal$q1 <- as.factor(dadosFinal$q1)
if (!require("doParallel")) {
install.packages("doParallel")
}
library(doParallel);
cl <- makeCluster(8);
dadosFinal <- subset(dadosFinal, select = -c(id, q1) )
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
#y <- factor(y, levels=c(0,1), labels=c(0, 1))
y
}
#teste com word count
dadosFinal <- apply(dadosFinal, 2, convert_count)
#options(max.print = 99999999)
#Carrega functions
library(tools)
source(file_path_as_absolute("functions.R"))
FILE_READ <- "testes/tweet_data_my.Rda"
FIT_SAVE <- "testes/tweet_fit_data_my.Rda"
dat = read.csv("testes/tweet_data_my.csv", header = TRUE)
save(dat, file = FILE_READ)
load(FILE_READ)
dadosFinal <- as.data.frame(dat)
#print("Resultado Final")
#initFileLog("aaaaa.txt")
#cols <- colnames(dadosFinal)
#cols[1:50]
#print(cols)
#finishFileLog("aaaaa.txt")
#dadosFinal <- as.data.frame(unclass(dadosFinal))
dadosFinal$q1 <- as.factor(dadosFinal$q1)
if (!require("doParallel")) {
install.packages("doParallel")
}
library(doParallel);
cl <- makeCluster(4);
dadosFinalM <- subset(dadosFinal, select = -c(id, q1) )
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
#y <- factor(y, levels=c(0,1), labels=c(0, 1))
y
}
#teste com word count
dadosFinalM <- apply(dadosFinalM, 2, convert_count)
dataP <- cbind.fill(dadosFinalM, dataFinal$q1)
dadosFinalM <- apply(dadosFinalM, 2, convert_count)
dataP <- cbind.fill(dadosFinalM, dataFinal$q1)
#options(max.print = 99999999)
#Carrega functions
library(tools)
source(file_path_as_absolute("functions.R"))
FILE_READ <- "testes/tweet_data_my.Rda"
FIT_SAVE <- "testes/tweet_fit_data_my.Rda"
dat = read.csv("testes/tweet_data_my.csv", header = TRUE)
save(dat, file = FILE_READ)
load(FILE_READ)
dadosFinal <- as.data.frame(dat)
#print("Resultado Final")
#initFileLog("aaaaa.txt")
#cols <- colnames(dadosFinal)
#cols[1:50]
#print(cols)
#finishFileLog("aaaaa.txt")
#dadosFinal <- as.data.frame(unclass(dadosFinal))
dadosFinal$q1 <- as.factor(dadosFinal$q1)
if (!require("doParallel")) {
install.packages("doParallel")
}
library(doParallel);
cl <- makeCluster(4);
dadosFinalM <- subset(dadosFinal, select = -c(id, q1) )
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
y
}
#teste com word count
dadosFinalM <- apply(dadosFinalM, 2, convert_count)
dataP <- cbind.fill(dadosFinalM, dataFinal$q1)
dataP <- cbind.fill(dadosFinalM, dadosFinal$q1)
if (!require("rowr")) {
install.packages("rowr")
}
library(rowr)
print("NV")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = subset(dadosP, select = -c(q1)),
y = dadosP$q1,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
print("Treinando")
fit <- trainAlgoritmo(dataP)
View(dataP)
dataP <- cbind.fill(dadosFinalM, subset(dadosFinal, select = c(q1)))
if (!require("rowr")) {
install.packages("rowr")
}
library(rowr)
print("NV")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = subset(dadosP, select = -c(q1)),
y = dadosP$q1,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
print("Treinando")
fit <- trainAlgoritmo(dataP)
dadosFinal$q1 <- as.factor(dadosFinal$q1)
dadosFinal$q1
#options(max.print = 99999999)
#Carrega functions
library(tools)
source(file_path_as_absolute("functions.R"))
FILE_READ <- "testes/tweet_data_my.Rda"
FIT_SAVE <- "testes/tweet_fit_data_my.Rda"
dat = read.csv("testes/tweet_data_my.csv", header = TRUE)
save(dat, file = FILE_READ)
load(FILE_READ)
dadosFinal <- as.data.frame(dat)
dadosFinal$q1
View(dadosFinal)
dat = read.csv("testes/tweet_data_my.csv", header = TRUE)
dat
View(dat)
dat$q1
dat
summary(dat)
library(tools)
options(max.print = 99999999)
summary(dat)
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
FILE_READ <- "testes/tweet_data_my.Rda"
FIT_SAVE <- "testes/tweet_fit_data_my.Rda"
dat = read.csv("testes/tweet_data_my.csv", header = TRUE)
summary(dat)
dat$q1
View(dat)
library(rJava)
install.packages(c("NLP", "openNLP", "RWeka", "qdap"))
