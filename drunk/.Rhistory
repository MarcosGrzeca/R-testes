nrow(dataM)
ncol(dataM)
for(i in 1:nrow(dataM)) {
for(j in 1:ncol(dataM)) {
dadosFinal[i][[cols[j]]] <- dataM[i, j]
}
}
dadosFinal[1][alc]
dadosFinal[1]["alc"]
cols
dadosFinal[1][cols[10]]
dadosFinal
dadosFinal[1][1]
dadosFinal[1][1]
dadosFinal[1, 1]
dadosFinal[1]["alc"]
dadosFinal[1]$"alc"
dadosFinal[1000]$"alc"
dadosFinal[1]$"alc"
dadosFinal[1000]$"alc"
dadosFinal[1]$"alc" <- "na"
dadosFinal[1]
dadosFinal[1]
dadosFinal[1]$"alc" <- "a"
dadosFinal[1]
dadosFinal[1000]$"alc"
for(i in 1:nrow(dataM)) {
for(j in 1:ncol(dataM)) {
dadosFinal[i][[cols[j]]] <- dataM[i, j]
}
}
dadosFinal
dataM
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
#y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
#y <- factor(y, levels=c(0,1), labels=c(0, 1))
y
}
dataM <- as.data.frame(as.matrix(dtm_train))
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
#y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
#y <- factor(y, levels=c(0,1), labels=c(0, 1))
y
}
dataM <- apply(dataM, 2, convert_count)
cols <- colnames(dataM)
dadosFinal <- subset(dados, select = -c(texto, id) )
nrow(dataM)
ncol(dataM)
dadosFinal
dataM
dump(dadosFinal, "dadosFinal.txt")
dump(dadosFinal, "dadosFinal.csv")
dump(dadosM, "dadosM.csv")
dump(dataM, "dadosM.csv")
dadosFinal <- read.csv(file="dadosM.csv", header=TRUE, sep=",")
dadosFinal
save(dataM,file="alemao.Rda")
dadosFinal[1:5,1:5]
source(file_path_as_absolute("classificadores.R"))
final <- classificar(dadosFinal)
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
dados <- query("(SELECT id, texto, alc, repetitions, longpauses FROM conversa WHERE alc = 'a' LIMIT 2000) UNION (SELECT id, texto, alc, repetitions, longpauses FROM conversa WHERE alc = 'na' LIMIT 2000)")
dados$alc[dados$alc == "cna"] <- "na"
dados$alc <- as.factor(dados$alc)
dados$texto <- gsub('"', 'aspas', dados$texto)
dados$repetitions[dados$repetitions > 0] <- 1
dados$repetitions[dados$repetitions == 0] <- 0
dados$longpauses[dados$longpauses > 0] <- 1
dados$longpauses[dados$longpauses == 0] <- 0
clearConsole()
library(text2vec)
library(data.table)
setDT(dados)
setkey(dados, id)
prep_fun = tolower
tok_fun = word_tokenizer
stop_words = c("aber", "als", "am", "an", "auch", "auf", "aus", "bei", "bin", "bis", "bist", "da", "dadurch", "daher", "darum", "das", "daß", "dass", "dein", "deine", "dem", "den", "der", "des", "dessen", "deshalb", "die", "dies", "dieser", "dieses", "doch", "dort", "du", "durch", "ein", "eine", "einem", "einen", "einer", "eines", "er", "es", "euer", "eure", "für", "hatte", "hatten", "hattest", "hattet", "hier", "hinter", "ich", "ihr", "ihre", "im", "in", "ist", "ja", "jede", "jedem", "jeden", "jeder", "jedes", "jener", "jenes", "jetzt", "kann", "kannst", "können", "könnt", "machen", "mein", "meine", "mit", "muß", "mußt", "musst", "müssen", "müßt", "nach", "nachdem", "nein", "nicht", "nun", "oder", "seid", "sein", "seine", "sich", "sie", "sind", "soll", "sollen", "sollst", "sollt", "sonst", "soweit", "sowie", "und", "unser", "unsere", "unter", "vom", "von", "vor", "wann", "warum", "was", "weiter", "weitere", "wenn", "wer", "werde", "werden", "werdet", "weshalb", "wie", "wieder", "wieso", "wir", "wird", "wirst", "wo", "woher", "wohin", "zu", "zum", "zur", "über")
it_train = itoken(dados$texto,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, stopwords = stop_words)
vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, vectorizer)
vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, vectorizer)
dataM <- as.data.frame(as.matrix(dtm_train))
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
#y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
#y <- factor(y, levels=c(0,1), labels=c(0, 1))
y
}
dataM <- apply(dataM, 2, convert_count)
cols <- colnames(dataM)
dadosFinal <- subset(dados, select = -c(texto, id) )
nrow(dataM)
ncol(dataM)
dump(dadosFinal, "dadosFinal.csv")
dump(dataM, "dadosM.csv")
dadosFinal <- read.csv(file="dadosM.csv", header=TRUE, sep=",")
save(dadosFinal,file="alemao.Rda")
source(file_path_as_absolute("classificadores.R"))
final <- classificar(dadosFinal)
load("alemao.Rda")
source(file_path_as_absolute("classificadores.R"))
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
source(file_path_as_absolute("classificadores.R"))
dadosFinal
fit <- nv_train(dadosFinal)
fit
bh_pred <- predict(fit, dadosFinal)
bh_pred
a <- table(bh_pred, dadosFinal$alc)
uarA <- a[1,1] / (a[1,1] + a[1,2])
uarNA <- a[2,2] / (a[2,2] + a[2,1])
if (uarNA == "NaN"){
uarNA = 0
}
uar = (uarA + uarNA) / 2
uar
View(dadosFinal)
a <- table(bh_pred, dadosFinal$alc)
a
bh_pred
library (ROCR);
RP.perf <- performance(bh_pred, "prec", "rec");
bh_pred
fit
bh_pred
pred2 <- prediction(bh_pred, dadosFinal$alc);
dadosFinal$alc
bh_pred
dadosFinal$alc
pred2 <- prediction(bh_pred, dadosFinal$alc);
precision <- posPredValue(bh_pred, dadosFinal$alc)
precision
recall <- sensitivity(bh_pred, dadosFinal$alc)
recall
F1 <- (2 * precision * recall) / (precision + recall)
F1
uar
paste("Precision", precision, sep="")
paste("Precision", precision, sep=" ")
precision <- posPredValue(bh_pred, dadosFinal$alc)
paste("Precision", precision, sep=" ")
recall <- sensitivity(bh_pred, dadosFinal$alc)
paste("Recall", recall, sep=" ")
F1 <- (2 * precision * recall) / (precision + recall)
paste("F1", F1, sep=" ")
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
dados <- query("(SELECT id, texto, alc, repetitions, longpauses FROM conversa WHERE alc = 'a' LIMIT 2000) UNION (SELECT id, texto, alc, repetitions, longpauses FROM conversa WHERE alc = 'na' LIMIT 2000)")
dados$alc[dados$alc == "cna"] <- "na"
dados$alc <- as.factor(dados$alc)
dados$texto <- gsub('"', 'aspas', dados$texto)
dados$repetitions[dados$repetitions > 0] <- 1
dados$repetitions[dados$repetitions == 0] <- 0
dados$longpauses[dados$longpauses > 0] <- 1
dados$longpauses[dados$longpauses == 0] <- 0
clearConsole()
library(text2vec)
library(data.table)
setDT(dados)
setkey(dados, id)
prep_fun = tolower
tok_fun = word_tokenizer
stop_words = c("aber", "als", "am", "an", "auch", "auf", "aus", "bei", "bin", "bis", "bist", "da", "dadurch", "daher", "darum", "das", "daß", "dass", "dein", "deine", "dem", "den", "der", "des", "dessen", "deshalb", "die", "dies", "dieser", "dieses", "doch", "dort", "du", "durch", "ein", "eine", "einem", "einen", "einer", "eines", "er", "es", "euer", "eure", "für", "hatte", "hatten", "hattest", "hattet", "hier", "hinter", "ich", "ihr", "ihre", "im", "in", "ist", "ja", "jede", "jedem", "jeden", "jeder", "jedes", "jener", "jenes", "jetzt", "kann", "kannst", "können", "könnt", "machen", "mein", "meine", "mit", "muß", "mußt", "musst", "müssen", "müßt", "nach", "nachdem", "nein", "nicht", "nun", "oder", "seid", "sein", "seine", "sich", "sie", "sind", "soll", "sollen", "sollst", "sollt", "sonst", "soweit", "sowie", "und", "unser", "unsere", "unter", "vom", "von", "vor", "wann", "warum", "was", "weiter", "weitere", "wenn", "wer", "werde", "werden", "werdet", "weshalb", "wie", "wieder", "wieso", "wir", "wird", "wirst", "wo", "woher", "wohin", "zu", "zum", "zur", "über")
it_train = itoken(dados$texto,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, stopwords = stop_words)
vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, vectorizer)
vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, vectorizer)
dataM <- as.matrix(dtm_train)
dataM
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
#y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
#y <- factor(y, levels=c(0,1), labels=c(0, 1))
y
}
dataM <- apply(dataM, 2, convert_count)
cols <- colnames(dataM)
dadosFinal <- subset(dados, select = -c(texto, id) )
for(i in 1:nrow(dataM)) {
for(j in 1:ncol(dataM)) {
dadosFinal[i][[cols[j]]] <- dataM[i, j]
}
}
require(data.table)
dadosFinal <- as.data.table(dadosFinal, keep.rownames=T)
for(i in 1:nrow(dataM)) {
for(j in 1:ncol(dataM)) {
dadosFinal[i][[cols[j]]] <- dataM[i, j]
}
}
dataM <- as.data.table(dataM, keep.rownames=T)
dadosFinal <- as.data.table(dadosFinal, keep.rownames=T)
for(i in 1:nrow(dataM)) {
for(j in 1:ncol(dataM)) {
dadosFinal[i][[cols[j]]] <- dataM[i, j]
}
}
nrow(dataM)
ncol(dataM)
for(i in 1:nrow(dataM)) {
for(j in 1:ncol(dataM)) {
dadosFinal[i][[cols[j]]] <- dataM[i, j]
}
}
dataM
dataM[0, 1]
dataM[1, 1]
dataM[1, 0]
dataM[1, 1:10]
dataM[1:10, 1:10]
dadosFinal[1:10, 1:10]
dataM[1:10, 1]
dataM[1, 1]
for(i in 1:nrow(dataM)) {
for(j in 1:ncol(dataM)) {
#dadosFinal[i][[cols[j]]] <- dataM[i, j]
dadosFinal[i, j] <- dataM[i, j]
}
}
dadosFinal[1, 1]
dataM[1, 1]
dadosFinal[1][rn] <- 10
dadosFinal[1][[rn] <- 10
for(i in 1:nrow(dataM)) {
for(j in 1:ncol(dataM)) {
#dadosFinal[i][[cols[j]]] <- dataM[i, j]
dadosFinal[i, j] <- dataM[i, j]
}
}
for(i in 1:ncol(dataM)) {
dadosFinal[[cols[i]]] <- as.integer(dadosFinal[[cols[i]]])
}
#require(data.table)
#dt.raw <- as.data.table(g.raw, keep.rownames=T)
#Data <- as.matrix(Data)
#save(dataM,file="alemao.Rda")
#load("alemao.Rda")
#dataM <- as.data.frame(unclass(dadosFinal))
#dataM <- as.data.frame(dataM)
#dataM$alc <- as.factor(dataM$alc)
#dataM$repetitions <- as.factor(dataM$repetitions)
#dataM$longpauses <- as.factor(dataM$longpauses)
#dadosFinal <- as.data.frame(dadosFinal)
save(dadosFinal,file="alemao.Rda")
load("alemao.Rda")
source(file_path_as_absolute("classificadores.R"))
fit <- nv_train(dadosFinal)
fit
bh_pred <- predict(fit, dadosFinal)
dadosFinal[1][[rn]] <- 10
dadosFinal[1]["rn"] <- 10
dadosFinal[1,  get("alc")] <- 10
dadosFinal[1, get("alc")] <- 10
dadosFinal
dadosFinal[1, get(alc)] <- 10
"
asdsasa
exit
sad
as
d
sda
dsa
sda""
"
dadosFinal[1, get("alc")] <- 10
dadosFinal[1, [["alc"]]] <- 10
dadosFinal[1, ["alc"]] <- 10
dadosFinal[1, get("alc")] <- 10
load("alemao.Rda")
View(dadosFinal)
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
dados <- query("(SELECT id, texto, alc, repetitions, longpauses FROM conversa WHERE alc = 'a' LIMIT 2000) UNION (SELECT id, texto, alc, repetitions, longpauses FROM conversa WHERE alc = 'na' LIMIT 2000)")
dados$alc[dados$alc == "cna"] <- "na"
dados$alc <- as.factor(dados$alc)
dados$texto <- gsub('"', 'aspas', dados$texto)
dados$repetitions[dados$repetitions > 0] <- 1
dados$repetitions[dados$repetitions == 0] <- 0
dados$longpauses[dados$longpauses > 0] <- 1
dados$longpauses[dados$longpauses == 0] <- 0
clearConsole()
library(text2vec)
library(data.table)
setDT(dados)
setkey(dados, id)
prep_fun = tolower
tok_fun = word_tokenizer
stop_words = c("aber", "als", "am", "an", "auch", "auf", "aus", "bei", "bin", "bis", "bist", "da", "dadurch", "daher", "darum", "das", "daß", "dass", "dein", "deine", "dem", "den", "der", "des", "dessen", "deshalb", "die", "dies", "dieser", "dieses", "doch", "dort", "du", "durch", "ein", "eine", "einem", "einen", "einer", "eines", "er", "es", "euer", "eure", "für", "hatte", "hatten", "hattest", "hattet", "hier", "hinter", "ich", "ihr", "ihre", "im", "in", "ist", "ja", "jede", "jedem", "jeden", "jeder", "jedes", "jener", "jenes", "jetzt", "kann", "kannst", "können", "könnt", "machen", "mein", "meine", "mit", "muß", "mußt", "musst", "müssen", "müßt", "nach", "nachdem", "nein", "nicht", "nun", "oder", "seid", "sein", "seine", "sich", "sie", "sind", "soll", "sollen", "sollst", "sollt", "sonst", "soweit", "sowie", "und", "unser", "unsere", "unter", "vom", "von", "vor", "wann", "warum", "was", "weiter", "weitere", "wenn", "wer", "werde", "werden", "werdet", "weshalb", "wie", "wieder", "wieso", "wir", "wird", "wirst", "wo", "woher", "wohin", "zu", "zum", "zur", "über")
it_train = itoken(dados$texto,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, stopwords = stop_words)
vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, vectorizer)
vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, vectorizer)
dataM <- as.data.frame(as.matrix(dtm_train))
cols <- colnames(dataM)
dadosFinal <- subset(dados, select = -c(texto, id) )
dump(dadosFinal, "count_dadosFinal.csv")
dump(dataM, "count_dadosM.csv")
dadosFinal <- read.csv(file="count_dadosM.csv", header=TRUE, sep=",")
save(dataM,file="alemao_count.Rda")
source(file_path_as_absolute("classificadores.R"))
final <- classificar(dadosFinal)
bh_pred
fit
bh_pred
source(file_path_as_absolute("classificadores.R"))
final <- classificar(dadosFinal)
final
source(file_path_as_absolute("classificadores.R"))
teste()
a <- teste()
final <- classificar(dadosFinal)
a <- teste()
a <- teste()
a
final
a <- teste()
a
source(file_path_as_absolute("classificadores.R"))
a <- teste()
a
source(file_path_as_absolute("classificadores.R"))
a <- teste()
a
source(file_path_as_absolute("classificadores.R"))
a <- teste()
a
vocab = create_vocabulary(it_train, ngram = c(1L, 2L), stopwords = stop_words)
library(text2vec)
library(data.table)
vocab = create_vocabulary(it_train, ngram = c(1L, 2L), stopwords = stop_words)
vocab
vocab = create_vocabulary(it_train, ngram = c(3L), stopwords = stop_words)
vocab = create_vocabulary(it_train, ngram = c(3L), stopwords = stop_words)
vocab = create_vocabulary(it_train, ngram = c(1L, 3L), stopwords = stop_words)
vocab
vocab = create_vocabulary(it_train, ngram = c(2L, 3L), stopwords = stop_words)
vocab
vocab = create_vocabulary(it_train, ngram = c(3L, 3L), stopwords = stop_words)
vocab
vocab = create_vocabulary(it_train, ngram = c(1L, 2L), stopwords = stop_words)
vocab
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
dados <- query("(SELECT id, texto, alc, repetitions, longpauses FROM conversa WHERE alc = 'a' LIMIT 2000) UNION (SELECT id, texto, alc, repetitions, longpauses FROM conversa WHERE alc = 'na' LIMIT 2000)")
dados$alc[dados$alc == "cna"] <- "na"
dados
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
dados <- query("SELECT id, texto, alc, repetitions, longpauses FROM conversa")
dados$alc[dados$alc == "cna"] <- "na"
dados$alc <- as.factor(dados$alc)
dados$texto <- gsub('"', 'aspas', dados$texto)
dados$repetitions[dados$repetitions > 0] <- 1
dados$repetitions[dados$repetitions == 0] <- 0
dados$longpauses[dados$longpauses > 0] <- 1
dados$longpauses[dados$longpauses == 0] <- 0
clearConsole()
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
dados <- query("SELECT id, texto, alc, repetitions, longpauses FROM conversa")
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
dados <- query("SELECT id, texto, alc, repetitions, longpauses FROM conversa")
dados$alc[dados$alc == "cna"] <- "na"
dados$alc <- as.factor(dados$alc)
dados$texto <- gsub('"', 'aspas', dados$texto)
save(dados, file="database.Rda")
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
load("database.Rda")
library(RMySQL)
clearConsole <- function(){
cat("\014")
}
initFileLog <- function(nome){
zz <- file(nome, open = "wt")
sink(zz)
sink(zz, type = "message")
}
finishFileLog <- function(nome){
sink(type = "message")
sink()
file.show(nome)
}
query <- function(sql) {
dbDataType(RMySQL::MySQL(), "a")
mydb = dbConnect(MySQL(), user='root', password='', dbname=DATABASE, host='localhost')
rs = dbSendQuery(mydb, sql);
dataBD <- fetch(rs, n=-1)
#dataBD <- fetch(rs, getNumRows(mydb, "WAVELENGTH"))
huh <- dbHasCompleted(rs)
dbClearResult(rs)
dbDisconnect(mydb)
return (dataBD)
}
print("glm")
options(max.print = 99999999)
library(tools)
source(file_path_as_absolute("functions.R"))
DATABASE <- "alemao"
clearConsole();
load("database.Rda")
dados$repetitions[dados$repetitions > 0] <- 1
dados$repetitions[dados$repetitions == 0] <- 0
dados$longpauses[dados$longpauses > 0] <- 1
dados$longpauses[dados$longpauses == 0] <- 0
clearConsole()
library(text2vec)
library(data.table)
setDT(dados)
setkey(dados, id)
prep_fun = tolower
tok_fun = word_tokenizer
stop_words = c("aber", "als", "am", "an", "auch", "auf", "aus", "bei", "bin", "bis", "bist", "da", "dadurch", "daher", "darum", "das", "daß", "dass", "dein", "deine", "dem", "den", "der", "des", "dessen", "deshalb", "die", "dies", "dieser", "dieses", "doch", "dort", "du", "durch", "ein", "eine", "einem", "einen", "einer", "eines", "er", "es", "euer", "eure", "für", "hatte", "hatten", "hattest", "hattet", "hier", "hinter", "ich", "ihr", "ihre", "im", "in", "ist", "ja", "jede", "jedem", "jeden", "jeder", "jedes", "jener", "jenes", "jetzt", "kann", "kannst", "können", "könnt", "machen", "mein", "meine", "mit", "muß", "mußt", "musst", "müssen", "müßt", "nach", "nachdem", "nein", "nicht", "nun", "oder", "seid", "sein", "seine", "sich", "sie", "sind", "soll", "sollen", "sollst", "sollt", "sonst", "soweit", "sowie", "und", "unser", "unsere", "unter", "vom", "von", "vor", "wann", "warum", "was", "weiter", "weitere", "wenn", "wer", "werde", "werden", "werdet", "weshalb", "wie", "wieder", "wieso", "wir", "wird", "wirst", "wo", "woher", "wohin", "zu", "zum", "zur", "über")
it_train = itoken(dados$texto,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = dados$id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, ngram = c(1L, 2L), stopwords = stop_words)
vocab = create_vocabulary(it_train, stopwords = stop_words)
vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, vectorizer)
dataM <- as.data.frame(as.matrix(dtm_train))
dadosFinal <- subset(dados, select = -c(texto, id) )
dump(dadosFinal, "exp1_alc.csv")
dump(dataM, "exp1_bag.csv")
dadosFinal <- read.csv(file="base_completa/exp1_bag.csv", header=TRUE, sep=",")
save(dadosFinal, file="alemao_base_completa.Rda")
library(tools)
PATH_FIT <- "rda/nv/fit.Rda"
PATH_PRED <- "rda/nv/bh_pred.Rda"
PATH_IMAGE <- "rda/nv/nv.RData"
load("rda/alemao_base_completa.Rda")
print("Naive Bayes")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = dadosP[,2:ncol(dadosP)],
y = dadosP$alc,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
source(file_path_as_absolute("classificador_default.R"))
source('~/GitHub/R-testes/drunk/nv.R')
PATH_PRED <- "rda/nv/bh_pred.Rda"
PATH_IMAGE <- "rda/nv/nv.RData"
load("rda/alemao_base_completa.Rda")
print("Naive Bayes")
library(caret)
trainAlgoritmo <- function(dadosP) {
fit_nv <- train(x = dadosP[,2:ncol(dadosP)],
y = dadosP$alc,
method = "nb",
trControl = trainControl(method = "cv", number = 10)
)
return (fit_nv)
}
source(file_path_as_absolute("classificador_default.R"))
stopwords = tm::stopwords("de")
stop_words = tm::stopwords("de")
stop_words
