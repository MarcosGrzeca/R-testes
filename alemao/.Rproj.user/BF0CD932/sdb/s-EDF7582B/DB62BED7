{
    "collab_server" : "",
    "contents" : "#Carregar bibliotecas\noptions(max.print = 99999999)\n\n#https://cran.r-project.org/web/packages/text2vec/vignettes/text-vectorization.html\n#Pr?-processar texto https://rpubs.com/MajstorMaestro/256588\n\n#Carrega functions\nDIRETORIO = \"C:\\\\Users\\\\Marcos\\\\Documents\\\\GitHub\\\\R-testes\\\\\"\nsource(file=paste(DIRETORIO,\"functions.R\", sep = \"\"))\n\n#Configura??es\nDATABASE <- \"alemao\"\nclearConsole();\ndados <- query(\"SELECT id, texto, alc FROM conversa\")\ndados$alc[dados$alc == \"cna\"] <- \"na\"\ndados$alc <- as.factor(dados$alc)\nstr(dados)\n\nclearConsole()\n\nlibrary(text2vec)\nlibrary(data.table)\n\nsetDT(dados)\nsetkey(dados, id)\nset.seed(2016L)\n\nprep_fun = tolower\ntok_fun = word_tokenizer\n\nstop_words = c(\"aber\",\"als\",\"am\",\"an\",\"auch\",\"auf\",\"aus\",\"bei\",\"bin\",\"bis\",\"bist\",\"da\",\"dadurch\",\"daher\",\"darum\",\"das\",\"da?\",\"dass\",\"dein\",\"deine\",\"dem\",\"den\",\"der\",\"des\",\"dessen\",\"deshalb\",\"die\",\"dies\",\"dieser\",\"dieses\",\"doch\",\"dort\",\"du\",\"durch\",\"ein\",\"eine\",\"einem\",\"einen\",\"einer\",\"eines\",\"er\",\"es\",\"euer\",\"eure\",\"f?r\",\"hatte\",\"hatten\",\"hattest\",\"hattet\",\"hier\",\"hinter\",\"ich\",\"ihr\",\"ihre\",\"im\",\"in\",\"ist\",\"ja\",\"jede\",\"jedem\",\"jeden\",\"jeder\",\"jedes\",\"jener\",\"jenes\",\"jetzt\",\"kann\",\"kannst\",\"k?nnen\",\"k?nnt\",\"machen\",\"mein\",\"meine\",\"mit\",\"mu?\",\"mu?t\",\"musst\",\"m?ssen\",\"m??t\",\"nach\",\"nachdem\",\"nein\",\"nicht\",\"nun\",\"oder\",\"seid\",\"sein\",\"seine\",\"sich\",\"sie\",\"sind\",\"soll\",\"sollen\",\"sollst\",\"sollt\",\"sonst\",\"soweit\",\"sowie\",\"und\",\"unser\",\"unsere\",\"unter\",\"vom\",\"von\",\"vor\",\"wann\",\"warum\",\"was\",\"weiter\",\"weitere\",\"wenn\",\"wer\",\"werde\",\"werden\",\"werdet\",\"weshalb\",\"wie\",\"wieder\",\"wieso\",\"wir\",\"wird\",\"wirst\",\"wo\",\"woher\",\"wohin\",\"zu\",\"zum\",\"zur\",\"?ber\")\n\nit_train = itoken(dados$texto, \n                  preprocessor = prep_fun, \n                  tokenizer = tok_fun, \n                  ids = dados$id, \n                  progressbar = TRUE)\n\nvocab = create_vocabulary(it_train, stopwords = stop_words)\n#vocab = create_vocabulary(it_train)\nvectorizer = vocab_vectorizer(vocab)\ndtm_train = create_dtm(it_train, vectorizer)\n\ncol_headings <- c('id','texto','alc')\nnames(dados) <- col_headings\n\nvectorizer = vocab_vectorizer(vocab)\nt1 = Sys.time()\ndtm_train = create_dtm(it_train, vectorizer)\nprint(difftime(Sys.time(), t1, units = 'sec'))\n#identical(rownames(dtm_train), dados$id)\n\ndata <- as.data.frame(as.matrix(dtm_train))\n\n\n\ntotal <- c(dados, data)\ntotal <- as.data.frame(total) \ntotal <- subset(total, select = -c(texto, id) )\n#export(total2, \"alemao_bag.csv\")\n\ntotal <- as.data.frame(unclass(total))\n\nexport(total, \"dump_enem_total.arff\")\n\nlibrary('caret')\n\ntrain_control <- trainControl(method=\"cv\", number=1)\n#create model\nfit <- train(alc~., data = total2, method = \"nb\", trControl=train_control)\nfit\n\n\n# load the library\nlibrary(caret)\n# load the iris dataset\ndata(iris)\n# define training control\ntrain_control <- trainControl(method=\"cv\", number=10)\n# fix the parameters of the algorithm\ngrid <- expand.grid(.fL=c(0), .usekernel=c(FALSE))\n# train the model\nmodel <- train(Species~., data=iris, trControl=train_control, method=\"nb\")\n# summarize results\nprint(model)\n             \nlibrary(glmnet)\nNFOLDS = 5\nt1 = Sys.time()\nglmnet_classifier = cv.glmnet(x = dtm_train, y = train[['alc']], \n                              family = 'binomial', \n                              # L1 penalty\n                              alpha = 1,\n                              # interested in the area under ROC curve\n                              type.measure = \"auc\",\n                              # 5-fold cross-validation\n                              nfolds = NFOLDS,\n                              # high value is less accurate, but has faster training\n                              thresh = 1e-3,\n                              # again lower number of iterations for faster training\n                              maxit = 1e3)\nprint(difftime(Sys.time(), t1, units = 'sec'))\n\nplot(glmnet_classifier)\n\nprint(paste(\"max AUC =\", round(max(glmnet_classifier$cvm), 4)))\n\n# Note that most text2vec functions are pipe friendly!\nit_test = test$texto %>% \n  prep_fun %>% \n  tok_fun %>% \n  itoken(ids = test$id, \n         # turn off progressbar because it won't look nice in rmd\n         progressbar = FALSE)\n\ndtm_test = create_dtm(it_test, vectorizer)\n\npreds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]\nglmnet:::auc(test$alc, preds)\n\n",
    "created" : 1497821128295.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3977115890",
    "id" : "DB62BED7",
    "lastKnownWriteTime" : 1497827698,
    "last_content_update" : 1497827698130,
    "path" : "~/GitHub/R-testes/alemao.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}